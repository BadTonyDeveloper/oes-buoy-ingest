# ðŸŒŠ OES Buoy Ingest

A serverless cloud-based data ingestion and transformation system for simulated ocean buoy data. This project demonstrates a modern data pipeline using AWS Lambda, S3, Glue, and CI/CD via GitHub Actions.

---

## ðŸ“ Project Structure

```bash
oes-buoy-ingest/
â”œâ”€â”€ lambda/
â”‚   â”œâ”€â”€ ingest/
â”‚   â”‚   â””â”€â”€ lambda_function.py        # Generates simulated buoy data and stores it in S3 (raw/)
â”‚   â””â”€â”€ convert/
â”‚       â””â”€â”€ convert_function.py       # Converts raw JSON files to Parquet in S3 (processed/)
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_lambda.py                # Unit tests using unittest + moto
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ deploy.yml                # CI/CD workflow
â”‚
â”œâ”€â”€ requirements.txt                 # Dependencies for production (Lambda)
â”œâ”€â”€ requirements-dev.txt            # Dev-only dependencies (e.g., moto for testing)
â”œâ”€â”€ README.md                        # This file
â””â”€â”€ .gitignore                       # Ignore rules
```

---

## ðŸš€ Lambda Deployment via GitHub Actions

Every push to the `main` branch automatically triggers the CI/CD workflow:

1. Installs runtime and dependencies
2. Runs unit tests
3. Packages and deploys two AWS Lambda functions:
   - **`lambda_function.py`** â†’ Ingests simulated sensor data
   - **`convert_function.py`** â†’ Converts raw `.json` files to `.parquet`

---

### ðŸ” GitHub Secrets Required

| Secret name               | Description                           |
|---------------------------|----------------------------------------|
| `AWS_ACCESS_KEY_ID`       | IAM access key                         |
| `AWS_SECRET_ACCESS_KEY`   | IAM secret key                         |
| `AWS_REGION`              | AWS region (e.g. `eu-west-3`)          |
| `LAMBDA_FUNCTION_NAME`    | Main ingestion Lambda function name    |

---

## ðŸ§ª Running Tests Locally

Make sure you have `moto` and `boto3` installed:

```bash
pip install -r requirements-dev.txt
python -m unittest discover tests
```

The test suite includes:
- Validation of Lambda S3 uploads
- Data range assertions
- Bucket mocking via `moto`

---

## â˜ï¸ AWS Services Used

- **AWS Lambda** â€“ Serverless function hosting
- **Amazon S3** â€“ Raw and processed data storage
- **AWS Glue** â€“ Schema inference and Data Catalog
- **Amazon Athena** â€“ SQL queries on S3 data
- **EventBridge Scheduler** â€“ Automatic weekly execution
- **CloudWatch Logs** â€“ Execution logging
- **IAM** â€“ Fine-grained role and policy control

---

## ðŸ“ˆ Features

- ðŸ” Weekly automation with EventBridge
- ðŸ“‚ Folder-based S3 data lake (`raw/`, `processed/`)
- ðŸ§¹ Converts JSON â†’ Parquet with Pandas + PyArrow
- âœ… Test-driven development
- ðŸ§ª Isolated local testing with `moto`
- ðŸ’¼ Production-ready GitHub Actions CI/CD

---

## ðŸ§  Planned Extensions

| Phase   | Feature                                  |
|---------|------------------------------------------|
| âœ… A     | Raw ingestion and transformation         |
| ðŸ”„ B     | Machine Learning training in Colab       |
| ðŸ“Š C     | Visual dashboards with Looker or Power BI|
| ðŸ›¡ï¸ D     | Access control, retention, monitoring    |

---

## ðŸ“¸ Screenshots

Screenshots and evidence of the setup are hosted in a [private OneDrive folder] and used in the final academic report.

> *Note: Screenshots are not tracked by Git for space and relevance reasons.*

---

## ðŸ‘¤ Author

**BadTonyDeveloper**  
CLD7302 â€“ Cloud Solutions  
Academic Year 2024/25  
The University of Boton

---

## ðŸ“„ License

This repository is for academic use only.  
All components are developed and deployed in a controlled educational environment.
